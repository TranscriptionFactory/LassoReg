---
title: "Simple-Run"
author: "Vignette Author"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simple-Run}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r load_packages, message = FALSE, warning = FALSE}

library(tidyverse)
library(usethis)
library(devtools)

# run this everytime - it will only install if there are updates to the package
devtools::install_github("TranscriptionFactory/LassoReg", force = F,
                         dependencies = F, quiet = T)

library(LassoReg, attach.required = T)
library(Matrix)

```

## Create Network modules
*Important* If you are creating the modules for your own data, you need to pass your dataframe with the
gene features to the getModules function.
Input is clustered ppi data generated with ClustalOne. Included in the package are inputs that should
work fine for many use cases. There are two cluster inputs that vary based on the average size of the clusters they contain. If you wish to cluster de-duplicated ppi data, the input passed to ClustalOne can be found as well.
```{r create_clusters, include = TRUE}

# get average size 6 clusters
cluster_input_avgSize6 = LassoReg::clustered_ppi_avgSize6

# uncomment to get average size 8 clusters
# cluster_input_avgSize8 = LassoReg::clustered_ppi_avgSize8

# uncomment to load all_ppis
# all_ppis = LassoReg::all_ppis


# To generate the network modules, call getModules
# uncomment and replace df with your dataframe name to use
# modules = LassoReg::getModules(cluster_input_avgSize6, df)

```


## Load data
First note: lambda here refers to a multiplier on the lambda chosen through cross validation.

Second note: some values of lambda may be too stringent for your data and result in no 
features being selected and a resulting error in calculating the svm. If this happens,
try using a smaller value. 
You can test multiple values for lambda during a run.
Here's some ideas for values to try (I usually increase/decrease in increments of 0.25) \\
  1. 0.75, 1.0, 1.25
  2. 0.5, 0.75, 1.0

If you're getting good classification, use larger values to reduce the number of features chosen.

In general, 
# Larger alpha/lambda values = fewer features selected
and vice versa
```{r load_data, include = TRUE}
# these are example network modules
df = as.data.frame(LassoReg::example_data)

lambdaValues = c(0.75)

# usually use
#lambdaValues = c(0.95, 1.0, 1.05)
```

## Run Lasso 
LASSO_GRID will return:
  - gridResults: contains the results chosen in each of the 10 runs (each run contains 10-fold cross validation), for each of the lambda values
  - lambdas: the lambdaValues tested
  - lasso_input: the dataframe used
  - vars: the chosen variables
```{r run_lasso, message = FALSE, warning = FALSE}

results = LassoReg::LASSO_Grid(df, lambdaValues = lambdaValues)

names(results)

```

## Analyze features
The chosen features can be found like this:
```{r analyze_features, include = TRUE, echo = TRUE}

chosen_vars = results$vars$chosen_vars

```

## Analyze Network Modules (omit this step if not using network modules)
The names of the network modules 
```{r analyze_nm, include = TRUE, echo = TRUE}

network_names = LassoReg::getNetworkNames(results)
print(network_names)

```

## Analyse Results
```{r analyze_results, include = TRUE}

plots = LassoReg::plotResults(results)

# multiple plots get returned.
# One PLS-DA plot is returned for each lambda value
```

```{r, fig.width = 8, fig.height = 4}
plots[[1]]
```

```{r, fig.width = 8, fig.height = 5}
plots[[2]]
```

```{r, fig.width = 8, fig.height = 5}
plots[[3]]
```
